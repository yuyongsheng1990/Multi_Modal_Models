{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41de0e7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:18:27.017123Z",
     "start_time": "2024-07-16T00:18:27.012138Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPT-4 generated codes\n",
    "# torch实现一个结合image和text的多模态model。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10577811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:18:41.972349Z",
     "start_time": "2024-07-16T00:18:41.969158Z"
    }
   },
   "source": [
    "## GPT-4 Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5c6aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:22:19.791082Z",
     "start_time": "2024-07-16T00:22:18.867613Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c7c27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:33:07.752946Z",
     "start_time": "2024-07-16T00:33:07.748956Z"
    }
   },
   "source": [
    "### model_construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f319672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:22:42.052635Z",
     "start_time": "2024-07-16T00:22:42.049316Z"
    }
   },
   "source": [
    "#### image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b107293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:26:25.628266Z",
     "start_time": "2024-07-16T00:26:25.623789Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fn = nn.Identity()  # 恒等函数\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ff1ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:26:31.701045Z",
     "start_time": "2024-07-16T00:26:31.696766Z"
    }
   },
   "source": [
    "#### text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "837d58f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:28:57.754986Z",
     "start_time": "2024-07-16T00:28:57.750000Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        return outputs.pooler_output  # 使用bert的pooling output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b508fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:29:12.138966Z",
     "start_time": "2024-07-16T00:29:12.135450Z"
    }
   },
   "source": [
    "#### multi-modal integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "477a7ea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T02:11:22.140913Z",
     "start_time": "2024-07-16T02:11:22.135418Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        self.image_model = ImageModel()\n",
    "        self.text_model = TextModel()\n",
    "        self.fc = nn.Linear(1768, 1)  # 假设是二分类任务\n",
    "    \n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.image_model(image)\n",
    "        print('image_features_shape: {}'.format(image_features.shape))\n",
    "        text_features = self.text_model(input_ids, attention_mask)\n",
    "        print('text_features_shape: {}'.format(text_features.shape))\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "        print('combined_features_shape: {}'.format(combined_features.shape))\n",
    "        output = self.fc(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69da791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:34:10.892155Z",
     "start_time": "2024-07-16T00:34:10.888525Z"
    }
   },
   "source": [
    "### data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc4360a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:36:09.603112Z",
     "start_time": "2024-07-16T00:36:09.598368Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df555cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:36:32.692047Z",
     "start_time": "2024-07-16T00:36:31.884900Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d0b7631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:50:57.620339Z",
     "start_time": "2024-07-16T00:50:57.616880Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(image, text):\n",
    "    image = image_transforms(image)\n",
    "    text_tokens = tokenizer(text, padding='max_length', max_length=128, truncation=True, return_tensors='pt')\n",
    "    return image, text_tokens['input_ids'].squeeze(), text_tokens['attention_mask'].squeeze(),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19853f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:38:55.983100Z",
     "start_time": "2024-07-16T00:38:55.979824Z"
    }
   },
   "source": [
    "### running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44dae26c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:39:27.005663Z",
     "start_time": "2024-07-16T00:39:27.002670Z"
    }
   },
   "outputs": [],
   "source": [
    "# image data\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11a1a5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:50:39.365039Z",
     "start_time": "2024-07-16T00:50:39.294226Z"
    }
   },
   "outputs": [],
   "source": [
    "image = Image.open('./data/five.jpg')\n",
    "text = 'five is a super pretty girl.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "213e91f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:52:03.045340Z",
     "start_time": "2024-07-16T00:52:02.944942Z"
    }
   },
   "outputs": [],
   "source": [
    "image, input_ids, attention_mask = preprocess_data(image, text)\n",
    "image = image.unsqueeze(0)  # 扩展batch dimension\n",
    "input_ids = input_ids.unsqueeze(0)\n",
    "attention_mask = attention_mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae55239a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T02:11:28.588414Z",
     "start_time": "2024-07-16T02:11:27.454039Z"
    }
   },
   "outputs": [],
   "source": [
    "# initilize model\n",
    "model = MultiModalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50fd18c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T00:54:39.571137Z",
     "start_time": "2024-07-16T00:54:39.565723Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义loss和optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbca358a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T02:11:30.302413Z",
     "start_time": "2024-07-16T02:11:29.928977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_features_shape: torch.Size([1, 1000])\n",
      "text_features_shape: torch.Size([1, 768])\n",
      "combined_features_shape: torch.Size([1, 1768])\n",
      "tensor([[-0.1499]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# feed-forward\n",
    "output = model(image, input_ids, attention_mask)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba13753f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T02:12:53.282827Z",
     "start_time": "2024-07-16T02:12:53.272473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da61b22e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T02:14:36.799059Z",
     "start_time": "2024-07-16T02:14:36.788782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7709, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# label\n",
    "label = torch.tensor([1.0])\n",
    "\n",
    "loss = criterion(output.squeeze(dim=-1), label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "328bc567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T02:15:11.253916Z",
     "start_time": "2024-07-16T02:15:10.311272Z"
    }
   },
   "outputs": [],
   "source": [
    "# BP\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a232035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T02:15:26.187837Z",
     "start_time": "2024-07-16T02:15:26.184751Z"
    }
   },
   "source": [
    "### save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ace02",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
